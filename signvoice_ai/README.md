# SignVoiceAI

Приложение для распознавания жестов глухонемых в реальном времени через веб-камеру с переводом в текст и озвучиванием голосом.

## Описание

SignVoiceAI использует компьютерное зрение и нейронные сети для:
- Захвата видео с веб-камеры
- Обнаружения жестов через Mediapipe Hands
- Классификации жестов через PyTorch модель
- Отображения результата на экране
- Озвучивания распознанных жестов

## Требования

- Python 3.8 или выше
- Веб-камера
- Операционная система: Windows, Linux или macOS

## Установка

1. Клонируйте или скачайте проект в папку `signvoice_ai`

2. Установите зависимости:

```bash
pip install -r requirements.txt
```

**Примечание**: Если у вас возникают проблемы с установкой PyTorch, установите его отдельно с официального сайта:
- Windows/Linux: https://pytorch.org/get-started/locally/
- Или используйте команду с сайта PyTorch для вашей конфигурации

## Использование

### Базовый запуск

Запуск из корневой папки проекта:
```bash
python main.py
```

Или запуск из папки signvoice_ai:
```bash
cd signvoice_ai
python main.py
```

Приложение откроет окно с видеопотоком с камеры и начнет распознавать жесты.

### Запуск с обученной моделью

Если у вас есть обученная модель:

```bash
python main.py --model path/to/model.pth
```

### Выбор камеры

Если у вас несколько камер, можно указать индекс:

```bash
python main.py --camera 1
```

### Управление в приложении

- **Q** - Выход из приложения
- **R** - Повторное озвучивание текущего распознанного жеста

## Структура проекта

```
signvoice_ai/
├── main.py                     # Главный файл приложения
├── train_collect_data.py       # Скрипт для сбора данных жестов
├── train_model.py              # Скрипт для обучения модели
├── model/
│   ├── __init__.py
│   └── gesture_model.py       # PyTorch модель для распознавания жестов
├── utils/
│   ├── __init__.py
│   ├── camera.py              # Модуль для работы с камерой
│   ├── speech.py              # Модуль для голосового вывода
│   └── gestures.py            # Модуль обработки жестов (Mediapipe)
├── requirements.txt           # Зависимости проекта
└── README.md                  # Этот файл
```

## Распознаваемые жесты

По умолчанию приложение распознает следующие жесты:
- **Hello** - Приветствие
- **Thanks** - Спасибо
- **Yes** - Да
- **No** - Нет
- **Love** - Люблю

## Режим заглушки

Если обученная модель не предоставлена, приложение работает в режиме заглушки:
- Используется случайный генератор жестов для демонстрации функционала
- Все компоненты (камера, отображение, озвучивание) работают корректно
- Это позволяет протестировать интерфейс перед обучением реальной модели

## Обучение модели

Проект включает готовые скрипты для сбора данных и обучения модели.

### Шаг 1: Сбор данных жестов

Для каждого жеста нужно собрать образцы (рекомендуется 50-100+ образцов на жест):

```bash
# Сбор данных для жеста "Hello"
python train_collect_data.py --gesture Hello --output data

# Сбор данных для жеста "Thanks"
python train_collect_data.py --gesture Thanks --output data

# Сбор данных для жеста "Yes"
python train_collect_data.py --gesture Yes --output data

# Сбор данных для жеста "No"
python train_collect_data.py --gesture No --output data

# Сбор данных для жеста "Love"
python train_collect_data.py --gesture Love --output data
```

**Как использовать скрипт сбора данных:**
1. Запустите скрипт для нужного жеста
2. Показывайте жест перед камерой
3. Нажмите **SPACE** для сохранения каждого образца
4. Нажмите **Q** для завершения сбора

Данные сохраняются в CSV файлы в папке `data/` (или указанной вами папке).

### Шаг 2: Обучение модели

После сбора данных обучите модель:

```bash
python train_model.py --data data --output models/gesture_model.pth
```

**Параметры обучения:**
- `--data`: Папка с CSV файлами данных (по умолчанию: `data`)
- `--output`: Путь для сохранения модели (по умолчанию: `models/gesture_model.pth`)
- `--epochs`: Количество эпох обучения (по умолчанию: 50)
- `--batch_size`: Размер батча (по умолчанию: 32)
- `--learning_rate`: Скорость обучения (по умолчанию: 0.001)
- `--test_size`: Доля тестовой выборки (по умолчанию: 0.2)

**Пример с параметрами:**
```bash
python train_model.py --data data --output models/gesture_model.pth --epochs 100 --batch_size 64
```

### Шаг 3: Использование обученной модели

После обучения используйте модель:

```bash
python main.py --model models/gesture_model.pth
```

## Архитектура модели

Модель `GestureClassifier` представляет собой простую нейронную сеть:
- **Входной слой**: 63 значения (21 точка × 3 координаты: x, y, z)
- **Скрытый слой**: 128 нейронов с ReLU активацией и Dropout (0.2)
- **Выходной слой**: 5 классов (соответствуют жестам)

## Нормализация координат

Координаты суставов нормализуются относительно запястья для повышения устойчивости к различным положениям руки и расстояниям от камеры.

## Технологии

- **OpenCV** - работа с камерой и обработка видео
- **Mediapipe Hands** - обнаружение и отслеживание руки
- **PyTorch** - нейронная сеть для классификации жестов
- **pyttsx3** - синтез речи для озвучивания текста
- **NumPy** - работа с массивами данных

## Устранение неполадок

### Камера не открывается
- Проверьте, что камера подключена и не используется другим приложением
- Попробуйте изменить индекс камеры: `python main.py --camera 1`

### Ошибки с PyTorch
- Установите PyTorch согласно инструкциям на https://pytorch.org
- Для CPU версии: `pip install torch torchvision`

### Ошибки с Mediapipe
- Обновите Mediapipe: `pip install --upgrade mediapipe`

### Ошибки с pyttsx3
- На Windows обычно работает из коробки
- На Linux может потребоваться: `sudo apt-get install espeak`
- На macOS может потребоваться настроить голоса

### Приложение работает медленно
- Уменьшите разрешение камеры в `utils/camera.py`
- Используйте GPU версию PyTorch если доступна
- Уменьшите частоту распознавания (обрабатывайте каждый N-й кадр)

## Лицензия

Этот проект создан в образовательных целях.

## Автор

SignVoiceAI - проект для распознавания жестов в реальном времени.

## Благодарности

- Mediapipe за библиотеку обнаружения рук
- PyTorch за фреймворк глубокого обучения
- OpenCV за библиотеку компьютерного зрения

